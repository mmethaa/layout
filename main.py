import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV # Added GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import xgboost as xgb # Import XGBoost

# --- Streamlit UI: File Uploader ---
st.title("üìê Smart Layout Predictor (ML Powered)")
st.write("‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (layoutdata.xlsx - Sheet1.csv) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢")

uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV ‡∏´‡∏£‡∏∑‡∏≠ Excel (Sheet1.csv)", type=["csv", "xlsx"])

df = None # Initialize df to None

if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file, sheet_name='Sheet1')
        else:
            st.error("‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .csv ‡∏´‡∏£‡∏∑‡∏≠ .xlsx")
            st.stop()

        df.columns = df.columns.str.strip()
        st.success("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")

    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå: {e}")
        st.stop()
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠")
    st.stop()

# --- Continue only if df is loaded ---
if df is not None:
    # --- 2. Unit Conversion (sqm ‚ûù sq. wah) ---
    sqm_to_sqwah = 0.25
    columns_to_convert = ['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢(‡∏ï‡∏£‡∏°)', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤(‡∏ï‡∏£‡∏°)', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô‡∏£‡∏ß‡∏°', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô(5%‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢)']
    for col in columns_to_convert:
        if col in df.columns:
            df[col] *= sqm_to_sqwah
        else:
            st.sidebar.warning(f"Column '{col}' not found for unit conversion. Skipping.")

    # --- 3. Setup House Area (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï) ---
    AREA_TH = 5 * 16 * sqm_to_sqwah
    AREA_BA = 10 * 16 * sqm_to_sqwah
    AREA_BD = 15 * 18 * sqm_to_sqwah

    house_types = ['‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°', '‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î', '‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß', '‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß3‡∏ä‡∏±‡πâ‡∏ô', '‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå']

    # --- 4. Data Preprocessing for Machine Learning ---

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Features (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡πâ‡∏ô)
    features = ['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)', '‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô', '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î']

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Targets (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏≤‡∏°)
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤(‡∏ï‡∏£‡∏°)' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    targets = ['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢(‡∏ï‡∏£‡∏°)', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏≠‡∏¢', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô‡∏£‡∏ß‡∏°', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤(‡∏ï‡∏£‡∏°)']
    for h_type in house_types:
        if h_type in df.columns:
            targets.append(h_type)
        else:
            st.sidebar.warning(f"Target column '{h_type}' not found in data. Skipping this target.")


    features = [f for f in features if f in df.columns]
    targets = [t for t in targets if t in t in df.columns]

    if not features:
        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö Features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        st.stop()
    if not targets:
        st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö Targets ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î")
        st.stop()

    X = df[features]
    y = df[targets]

    # Handle potential missing categorical values in input data (fill with mode for training)
    # Ensure all features have no NaN before processing with pipeline
    for col in ['‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô', '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î']:
        if col in X.columns:
            if X[col].isnull().any():
                mode_val = X[col].mode()[0]
                X[col] = X[col].fillna(mode_val)
                st.sidebar.info(f"Filled missing values in '{col}' with mode: {mode_val}")

    # Handle potential missing numerical values (e.g., in ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°) if any)
    for col in ['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)']:
        if col in X.columns:
            if X[col].isnull().any():
                mean_val = X[col].mean()
                X[col] = X[col].fillna(mean_val)
                st.sidebar.info(f"Filled missing values in '{col}' with mean: {mean_val:.2f}")


    categorical_features = [col for col in ['‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô', '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'] if col in X.columns]
    numerical_features = [col for col in ['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'] if col in X.columns]

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numerical_features),
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
        ],
        remainder='passthrough'
    )

    # --- 5. Model Training ---

    # Allow user to select model type
    st.sidebar.subheader("‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    model_type = st.sidebar.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÇ‡∏°‡πÄ‡∏î‡∏•", ["RandomForestRegressor", "XGBRegressor"])

    if model_type == "RandomForestRegressor":
        regressor = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
        # Parameters for GridSearchCV (can be tuned)
        # param_grid = {
        #     'regressor__n_estimators': [100, 200, 300],
        #     'regressor__max_depth': [None, 10, 20],
        #     'regressor__min_samples_split': [2, 5],
        # }
    elif model_type == "XGBRegressor":
        # XGBoost handles multi-output directly, but requires a slight wrapper for scikit-learn pipeline for multiple targets
        # For multi-output with XGBoost, it's often better to train separate models for each target
        # Or use a multi-output wrapper if the targets are independent enough for this.
        # For simplicity with pipeline, we'll let XGBoost handle it, which it does well for common cases.
        regressor = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, random_state=42, n_jobs=-1)
        # Parameters for GridSearchCV (can be tuned)
        # param_grid = {
        #     'regressor__n_estimators': [100, 200, 300],
        #     'regressor__learning_rate': [0.05, 0.1, 0.2],
        #     'regressor__max_depth': [3, 5, 7],
        # }

    model = Pipeline(steps=[('preprocessor', preprocessor),
                            ('regressor', regressor)
                           ])

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    st.sidebar.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    with st.spinner(f'‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_type}...'):
        try:
            model.fit(X_train, y_train)
            st.sidebar.success(f"‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• {model_type} ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

            # Example of how to use GridSearchCV (uncomment if you want to run it, it takes time)
            # if 'param_grid' in locals(): # Check if param_grid was defined for the selected model
            #     st.sidebar.write("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Hyperparameter Tuning (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤)...")
            #     grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, scoring='r2', verbose=1)
            #     grid_search.fit(X_train, y_train)
            #     st.sidebar.success(f"Tuning ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! Best R2: {grid_search.best_score_:.4f}")
            #     st.sidebar.write("Best parameters:", grid_search.best_params_)
            #     model = grid_search.best_estimator_ # Use the best model found

        except Exception as e:
            st.sidebar.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
            st.stop()

    # --- 6. Model Evaluation ---
    st.sidebar.subheader("üìä ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö)")
    try:
        y_pred_test = model.predict(X_test)
        # Ensure y_pred_test is a DataFrame for consistent column access
        y_pred_test_df = pd.DataFrame(y_pred_test, columns=targets, index=y_test.index)

        for i, target_col in enumerate(targets):
            actual_test_target = y_test[target_col].values
            predicted_test_target = y_pred_test_df[target_col].values

            mae_val = mean_absolute_error(actual_test_target, predicted_test_target)
            r2_val = r2_score(actual_test_target, predicted_test_target)

            st.sidebar.write(f"**Target: {target_col}**")
            st.sidebar.markdown(f"- **MAE:** {mae_val:,.2f}")
            st.sidebar.markdown(f"- **R¬≤:** {r2_val:.4f}")
    except Exception as e:
        st.sidebar.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")


    # --- 7. Prediction Function (‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• ML) ---
    def predict_with_ml(project_area, land_shape, grade, province, ml_model, house_types_list, target_cols):
        input_data = pd.DataFrame([[project_area, land_shape, grade, province]],
                                  columns=['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)', '‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô', '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'])

        predicted_values = ml_model.predict(input_data)[0]

        predicted_dict = {target: value for target, value in zip(target_cols, predicted_values)}

        result = {
            '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏£.‡∏ß‡∏≤)': round(project_area, 2),
            '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢ (‡∏ï‡∏£.‡∏ß‡∏≤)': round(predicted_dict.get('‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢(‡∏ï‡∏£‡∏°)', 0), 2),
            '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô (‡∏ï‡∏£.‡∏ß‡∏≤)': round(predicted_dict.get('‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô‡∏£‡∏ß‡∏°', 0), 2),
            '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞ (‡∏ï‡∏£.‡∏ß‡∏≤)': round(predicted_dict.get('‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤(‡∏ï‡∏£‡∏°)', 0), 2), # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
            '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏ß‡∏°': max(0, int(round(predicted_dict.get('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á', 0)))),
            '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏≠‡∏¢': max(1, int(round(predicted_dict.get('‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏≠‡∏¢', 0))))
        }

        for h_type in house_types_list:
            col_name = h_type
            if col_name in predicted_dict:
                result[f'‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏õ‡∏•‡∏á ({h_type})'] = max(0, int(round(predicted_dict[col_name])))
            else:
                result[f'‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏õ‡∏•‡∏á ({h_type})'] = 0

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô: ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÉ‡∏ä‡πâ 5% ‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏î‡πâ
        avg_garden_ratio_of_dist = 0.05
        result['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô (‡∏ï‡∏£.‡∏ß‡∏≤)'] = round(result['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢ (‡∏ï‡∏£.‡∏ß‡∏≤)'] * avg_garden_ratio_of_dist, 2)

        return result

    # --- 8. Streamlit UI: Input and Prediction ---
    st.write("‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• Machine Learning.")

    # Input fields
    # Ensure min/max/default values for number_input are floats and handle cases where X might be empty initially
    project_area_input = st.number_input("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏£.‡∏ß‡∏≤)",
                                         min_value=float(X['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'].min()) if '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)' in X.columns and not X['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'].empty else 1000.0,
                                         max_value=float(X['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'].max()) if '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)' in X.columns and not X['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'].empty else 100000.0,
                                         value=float(X['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'].mean()) if '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)' in X.columns and not X['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'].empty else 40000.0,
                                         step=500.0)

    land_shape_options = X['‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô'].dropna().unique().tolist() if '‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô' in X.columns and not X['‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô'].empty else ['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏']
    land_shape_input = st.selectbox("‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô", land_shape_options)

    grade_options = X['‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£'].dropna().unique().tolist() if '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£' in X.columns and not X['‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£'].empty else ['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏£‡∏∞‡∏ö‡∏∏']
    grade_input = st.selectbox("‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£", grade_options)

    province_options = X['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'].dropna().unique().tolist() if '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in X.columns and not X['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'].empty else ['‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏']
    province_input = st.selectbox("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", province_options)

    if st.button("‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏±‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ ML"):
        # Basic validation for selected options
        # Check if selected values are actually in the options list for safety
        if land_shape_input not in land_shape_options or \
           grade_input not in grade_options or \
           province_input not in province_options:
            st.warning("‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥")

        result_ml = predict_with_ml(
            project_area_input,
            land_shape_input,
            grade_input,
            province_input,
            model,
            house_types,
            targets
        )
        st.subheader("üîç ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å ML")
        st.dataframe(pd.DataFrame(result_ml.items(), columns=['‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£', '‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢']), use_container_width=True)

        st.info("‡πÇ‡∏õ‡∏£‡∏î‡∏ó‡∏£‡∏≤‡∏ö: ‡∏Ñ‡πà‡∏≤ MAE ‡πÅ‡∏•‡∏∞ R¬≤ ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏Ñ‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡πÜ ‡∏ô‡∏µ‡πâ")
